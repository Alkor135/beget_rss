#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# minute_prepare.py

"""
–°—Ü–µ–Ω–∞—Ä–∏–π –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ñ—å—é—á–µ—Ä—Å—É –Ω–∞ –∏–Ω–¥–µ–∫—Å –†–¢–° (RTS),
—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö SQLite-–±–∞–∑–∞—Ö. –°–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞—Å—á—ë—Ç:
‚Ä¢ H2 ‚Äî –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞ –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã—Ç–∏—è;
‚Ä¢ H2_abs ‚Äî –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ H2;
‚Ä¢ Percentile ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å H2_abs –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö 10 —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π.
Percentile —Ç–µ–ø–µ—Ä—å –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π (–≥–¥–µ –æ–Ω –µ—â—ë –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω).
"""

import sqlite3
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
import glob
import logging
import yaml

# –ü—É—Ç—å –∫ settings.yaml –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —á—Ç–æ –∏ —Å–∫—Ä–∏–ø—Ç
SETTINGS_FILE = Path(__file__).parent / "settings_rts.yaml"

# –ß—Ç–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
    settings = yaml.safe_load(f)

# =======================
# –ù–ê–°–¢–†–û–ô–ö–ò
# =======================

TICKER = settings.get("ticker", "RTS")
SOURCE_DIR = Path(settings.get("path_db_dir", ""))   # –ü–∞–ø–∫–∞, –≥–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–µ –±–∞–∑—ã SQLite
SOURCE_MASK = settings['path_db_min_file'].replace('{ticker}', TICKER)  # –ú–∞—Å–∫–∞ –ø–æ–∏—Å–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
LOOKBACK_DAYS = 10                                 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ Percentile
TARGET_DB = f"minutes_RTS_processed_p{LOOKBACK_DAYS}.db"  # –ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–π –±–∞–∑—ã
LOG_FILE = "minute_prepare.log"                    # –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –ª–æ–≥–æ–≤

# =======================
# –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
# =======================

# –°–æ–∑–¥–∞—ë–º –ª–æ–≥–≥–µ—Ä
logger = logging.getLogger("minute_prepare")
logger.setLevel(logging.INFO)
formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

# –õ–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å
ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
ch.setFormatter(formatter)
logger.addHandler(ch)

# –õ–æ–≥ –≤ —Ñ–∞–π–ª
fh = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
fh.setLevel(logging.INFO)
fh.setFormatter(formatter)
logger.addHandler(fh)

# =======================
# –§–£–ù–ö–¶–ò–ò
# =======================

def create_target_table(conn):
    """–°–æ–∑–¥–∞—ë—Ç —Ç–∞–±–ª–∏—Ü—É —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –µ—Å–ª–∏ –æ–Ω–∞ –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    conn.execute("""
        CREATE TABLE IF NOT EXISTS FuturesProcessed (
            TRADEDATE TEXT PRIMARY KEY UNIQUE NOT NULL,
            SECID TEXT,
            OPEN REAL,
            LOW REAL,
            HIGH REAL,
            CLOSE REAL,
            VOLUME INTEGER,
            LSTTRADE TEXT,
            H2 REAL,
            H2_abs REAL,
            Percentile REAL
        )
    """)
    conn.commit()


def process_H2(df):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞ (H2) –∏ –µ–≥–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (H2_abs)."""
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –º–µ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞
    df["TRADEDATE_2h"] = df["TRADEDATE"] + timedelta(hours=2)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ —Å–¥–≤–∏–Ω—É—Ç—ã–º–∏ –Ω–∞ 2 —á–∞—Å–∞ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ CLOSE
    df_future = df[["TRADEDATE", "SECID", "CLOSE"]].rename(
        columns={"TRADEDATE": "TRADEDATE_future", "CLOSE": "CLOSE_future"}
    )

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—É—â–∏–µ –∏ –±—É–¥—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df = df.merge(df_future, left_on=["TRADEDATE_2h", "SECID"],
                  right_on=["TRADEDATE_future", "SECID"], how="left")

    # –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ü–µ–Ω–æ–π —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞ –∏ —Ü–µ–Ω–æ–π –æ—Ç–∫—Ä—ã—Ç–∏—è
    df["H2"] = df["CLOSE_future"] - df["OPEN"]

    # –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
    df["H2_abs"] = df["H2"].abs()

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    df.drop(columns=["TRADEDATE_2h", "TRADEDATE_future", "CLOSE_future"], inplace=True)

    return df


def compute_percentile(df, lookback_days):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –¥–ª—è H2_abs –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö lookback_days —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π.
    –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –≤—ã—Ä–∞–∂–∞–µ—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0.0, 1.0].
    """
    df = df.sort_values("TRADEDATE").reset_index(drop=True)
    df["Percentile"] = None
    df["TRADEDATE_DATE"] = df["TRADEDATE"].dt.date

    # –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–∞—Ç
    unique_dates = df["TRADEDATE_DATE"].drop_duplicates().tolist()
    date_to_idx = {date: i for i, date in enumerate(unique_dates)}

    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
    pbar = tqdm(total=len(df), desc="–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Percentile")

    for idx, row in df.iterrows():
        current_date = row["TRADEDATE_DATE"]
        current_idx = date_to_idx[current_date]

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–∫–Ω–æ lookback_days (–ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–µ –¥–Ω–∏)
        start_idx = max(0, current_idx - lookback_days)
        lookback_dates = unique_dates[start_idx:current_idx]

        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–Ω–µ–π ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –Ω–µ –≤—ã—á–∏—Å–ª—è–µ–º
        if not lookback_dates:
            df.at[idx, "Percentile"] = None
        else:
            pool = df[df["TRADEDATE_DATE"].isin(lookback_dates)]["H2_abs"].dropna()

            if len(pool) == 0:
                df.at[idx, "Percentile"] = None
            else:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–ª—é –∑–Ω–∞—á–µ–Ω–∏–π, –Ω–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–∏—Ö —Ç–µ–∫—É—â–µ–µ
                rank = (pool <= row["H2_abs"]).sum()
                df.at[idx, "Percentile"] = rank / len(pool)

        pbar.update(1)

    pbar.close()
    df.drop(columns=["TRADEDATE_DATE"], inplace=True)
    return df


# =======================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# =======================

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤."""
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –≤—ã—Ö–æ–¥–Ω–æ–π –±–∞–∑–µ
    with sqlite3.connect(TARGET_DB) as conn_target:
        create_target_table(conn_target)

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        source_files = sorted(glob.glob(str(Path(SOURCE_DIR) / SOURCE_MASK)))

        for src_file in source_files:
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞–∑—ã: {src_file}")

            with sqlite3.connect(src_file) as conn_src:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –º–∏–Ω—É—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                df_src = pd.read_sql("SELECT * FROM Futures", conn_src,
                                     parse_dates=["TRADEDATE", "LSTTRADE"])

                # –û—Ç–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â—ë –Ω–µ—Ç –≤ —Ü–µ–ª–µ–≤–æ–π –±–∞–∑–µ
                existing_dates = pd.read_sql(
                    "SELECT TRADEDATE FROM FuturesProcessed", conn_target
                )["TRADEDATE"]
                df_src = df_src[~df_src["TRADEDATE"].astype(str).isin(existing_dates)]

                if df_src.empty:
                    logger.info(f"–ù–µ—Ç –Ω–æ–≤—ã—Ö –±–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ {src_file}")
                    continue

                # === –†–∞—Å—á—ë—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞ 2 —á–∞—Å–∞ ===
                logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ H2 / H2_abs ({len(df_src)} –∑–∞–ø–∏—Å–µ–π)")
                df_src = process_H2(df_src)

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑—É
                df_src.to_sql("FuturesProcessed", conn_target, if_exists="append", index=False)
                logger.info(f"–°–æ—Ö—Ä–∞–Ω–∏–ª–∏ H2 / H2_abs –≤ {TARGET_DB}")

                # === –ù–æ–≤—ã–π –±–ª–æ–∫: –≤—ã–±–æ—Ä–æ—á–Ω—ã–π —Ä–∞—Å—á—ë—Ç Percentile ===
                logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Percentile (–æ–∫–Ω–æ {LOOKBACK_DAYS} –¥–Ω–µ–π)")

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –∏–º–µ—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è lookback
                df_all = pd.read_sql("SELECT * FROM FuturesProcessed", conn_target,
                                     parse_dates=["TRADEDATE", "LSTTRADE"])

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –±–µ–∑ Percentile
                df_new = df_all[df_all["Percentile"].isna()].copy()

                if df_new.empty:
                    logger.info("–ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –±–µ–∑ Percentile –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—á—ë—Ç")
                else:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
                    last_new_date = df_new["TRADEDATE"].max().date()

                    # –ë–µ—Ä—ë–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback_days + 1 –¥–µ–Ω—å
                    min_date_for_context = last_new_date - timedelta(days=LOOKBACK_DAYS + 1)
                    df_context = df_all[df_all["TRADEDATE"].dt.date <= last_new_date]
                    df_context = df_context[df_context["TRADEDATE"].dt.date >= min_date_for_context]

                    # –°—á–∏—Ç–∞–µ–º Percentile —Ç–æ–ª—å–∫–æ –Ω–∞ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                    df_context = compute_percentile(df_context, LOOKBACK_DAYS)

                    # –ò–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                    updated_rows = df_context[df_context["TRADEDATE"].isin(df_new["TRADEDATE"])]
                    logger.info(f"–û–±–Ω–æ–≤–ª—è–µ–º {len(updated_rows)} –∑–∞–ø–∏—Å–µ–π —Å –Ω–æ–≤—ã–º–∏ Percentile")

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ SQL UPDATE
                    with conn_target:
                        for _, row in updated_rows.iterrows():
                            conn_target.execute(
                                "UPDATE FuturesProcessed SET Percentile = ? WHERE TRADEDATE = ?",
                                (row["Percentile"], row["TRADEDATE"].strftime("%Y-%m-%d %H:%M:%S"))
                            )

                    logger.info("‚úÖ Percentile –æ–±–Ω–æ–≤–ª–µ–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")

                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ–º VACUUM ‚Üí {TARGET_DB}")
                conn_target.execute("VACUUM")

        logger.info("üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

# =======================
# –¢–û–ß–ö–ê –í–•–û–î–ê
# =======================

if __name__ == "__main__":
    start_time = datetime.now()
    logger.info("===== –ó–∞–ø—É—Å–∫ process_quotes.py =====")
    main()
    end_time = datetime.now()
    logger.info(f"===== –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time} =====")
