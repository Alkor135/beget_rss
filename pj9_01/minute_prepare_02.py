#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# minute_prepare.py
"""
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Ñ—å—é—á–µ—Ä—Å—É RTS –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö SQLite-–±–∞–∑ –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏.
–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–æ–∫ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç—Å—è –∫–ª—é—á–æ–º TRADEDATE (–≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ë–î –ø–æ–ª–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ).

–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è:
- H2 ‚Äî –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞ –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã—Ç–∏—è, –¥–æ–ø—É—Å–∫ ¬±2 –º–∏–Ω—É—Ç—ã;
- perc_25 ‚Äî 25 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å H2 –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö LOOKBACK_DAYS —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π;;
- perc_75 ‚Äî 75 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å H2 –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö LOOKBACK_DAYS —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π;;
"""

import sqlite3
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
import glob
import logging
import yaml
from collections import deque

# =======================
# –ù–ê–°–¢–†–û–ô–ö–ò –ò –õ–û–ì–ò
# =======================

SETTINGS_FILE = Path(__file__).parent / "settings_rts.yaml"
with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
    settings = yaml.safe_load(f)

TICKER = settings.get("ticker", "RTS")
SOURCE_DIR = Path(settings.get("path_db_dir", ""))              # –ü–∞–ø–∫–∞ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ SQLite
SOURCE_MASK = settings["path_db_min_file"].replace("{ticker}", TICKER)  # –ú–∞—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
LOOKBACK_BARS = int(settings.get("lookback_bars", 8000))

TARGET_PKL = f"minutes_{TICKER}_processed_p{LOOKBACK_BARS}.pkl"
LOG_FILE = "minute_prepare.log"

logger = logging.getLogger("minute_prepare_pkl")
logger.setLevel(logging.INFO)
formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")

ch = logging.StreamHandler()
ch.setLevel(logging.INFO)
ch.setFormatter(formatter)
logger.addHandler(ch)

fh = logging.FileHandler(LOG_FILE, mode="a", encoding="utf-8")
fh.setLevel(logging.INFO)
fh.setFormatter(formatter)
logger.addHandler(fh)

# =======================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï
# =======================

def ensure_datetime(df: pd.DataFrame, cols):
    for c in cols:
        if c in df.columns and not pd.api.types.is_datetime64_any_dtype(df[c]):
            df[c] = pd.to_datetime(df[c], errors="coerce")
    return df

def process_H2_nearest(df: pd.DataFrame) -> pd.DataFrame:
    # –¢—Ä–µ–±—É—é—Ç—Å—è TRADEDATE, OPEN, CLOSE
    df = df.sort_values('TRADEDATE').reset_index(drop=True)

    # –¶–µ–ª—å: –≤—Ä–µ–º—è —á–µ—Ä–µ–∑ 2 —á–∞—Å–∞
    df['TRADEDATE2h'] = df['TRADEDATE'] + pd.Timedelta(hours=2)

    # –ë—É–¥—É—â–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ –±–∞—Ä–∞
    future = df[['TRADEDATE', 'CLOSE']].rename(
        columns={'TRADEDATE': 'TRADEDATEfuture', 'CLOSE': 'CLOSEfuture'}
    ).sort_values('TRADEDATEfuture')

    # merge_asof: –±–ª–∏–∂–∞–π—à–∞—è –º–∏–Ω—É—Ç–∞, –¥–æ–ø—É—Å–∫ ¬±2 –º–∏–Ω—É—Ç—ã
    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ: –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∫–ª—é—á—É —Å–ª–∏—è–Ω–∏—è
    merged = pd.merge_asof(
        left=df.sort_values('TRADEDATE2h'),
        right=future,
        left_on='TRADEDATE2h',
        right_on='TRADEDATEfuture',
        direction='nearest',
        tolerance=pd.Timedelta('2min')
    )

    # –í–æ–∑–≤—Ä–∞—Ç –≤ –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–æ TRADEDATE –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏
    merged = merged.sort_values('TRADEDATE').reset_index(drop=True)

    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    merged['H2'] = merged['CLOSEfuture'] - merged['OPEN']
    # merged['H2_abs'] = merged['H2'].abs()

    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —É–¥–∞–ª–∏—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ
    merged.drop(columns=['TRADEDATEfuture'], inplace=True)

    return merged[['TRADEDATE', 'OPEN', 'CLOSE', 'H2']]


def add_percentile_prev_trading_bars(df: pd.DataFrame, bars_back: int = 8000) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏:
      - perc_25: 25-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å H2 –ø–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º bars_back –±–∞—Ä–∞–º (–∏—Å–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –±–∞—Ä)
      - perc_75: 75-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å H2 –ø–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–º bars_back –±–∞—Ä–∞–º (–∏—Å–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π –±–∞—Ä)

    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
      - –í df –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏ ['TRADEDATE', 'H2'].
      - df –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ 'TRADEDATE' –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
      - bars_back: —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –±–∞—Ä–æ–≤ –Ω–∞–∑–∞–¥.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - –ò—Å—Ö–æ–¥–Ω—ã–π df —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'perc_25' –∏ 'perc_75'.
    """
    if 'H2' not in df.columns:
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∞ 'H2' –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π.")

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    df = df.sort_values('TRADEDATE').reset_index(drop=True)

    # –ß—Ç–æ–±—ã –Ω–µ –≤–∫–ª—é—á–∞—Ç—å —Ç–µ–∫—É—â–∏–π –±–∞—Ä –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É ‚Äî —Å–¥–≤–∏–≥–∞–µ–º —Ä—è–¥ –Ω–∞ 1
    h2_prev = df['H2'].shift(1)

    # –ö–∞—Ç–µ–≥–æ—Ä–∏—á–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º rolling –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —á–∏—Å–ª—É –±–∞—Ä–æ–≤ (–∞ –Ω–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏),
    # —Ç–∞–∫ –∫–∞–∫ –º–∏–Ω—É—Ç–∞ ‚Äî –∫—Ä–∞—Ç–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, –∏ –Ω—É–∂–Ω–∞ —Ç–æ—á–Ω–∞—è –¥–ª–∏–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏.
    # min_periods –º–æ–∂–Ω–æ –≤—ã—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ —Ä–∞–∑—É–º–Ω—ã–π –ø–æ—Ä–æ–≥, –Ω–∞–ø—Ä–∏–º–µ—Ä 50, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —à—É–º–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ.
    window = h2_prev.rolling(window=bars_back, min_periods=max(1, min(50, bars_back)))

    # –ë—ã—Å—Ç—Ä—ã–µ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏ –∏–∑ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞
    df['perc_25'] = window.quantile(0.25)
    df['perc_75'] = window.quantile(0.75)

    return df

def save_all(df: pd.DataFrame):
    df = df.sort_values("TRADEDATE").drop_duplicates(subset=["TRADEDATE"], keep="last")
    df = df.reset_index(drop=True)
    Path(TARGET_PKL).parent.mkdir(parents=True, exist_ok=True)
    df.to_pickle(TARGET_PKL)
    logger.info(f"üéØ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {TARGET_PKL}")


# =======================
# –û–°–ù–û–í–ù–û–ô –ü–†–û–¶–ï–°–°
# =======================

def main():
    start = datetime.now()
    logger.info("===== –ó–∞–ø—É—Å–∫ minute_prepare.py =====")

    df_all = pd.DataFrame()

    source_files = sorted(glob.glob(str(Path(SOURCE_DIR) / SOURCE_MASK)))
    if not source_files:
        logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –ø–æ –º–∞—Å–∫–µ: {Path(SOURCE_DIR) / SOURCE_MASK}")

    for src_file in source_files:
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞–∑—ã: {src_file}")
        with sqlite3.connect(src_file) as conn_src:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏ –ë–ï–ó SECID
            df_src = pd.read_sql(
                "SELECT TRADEDATE, OPEN, CLOSE FROM Futures",
                conn_src,
                parse_dates=["TRADEDATE"],
            )

        df_src = ensure_datetime(df_src, ["TRADEDATE"])

        # –§–∏–ª—å—Ç—Ä –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫: –≤ –∏—Å—Ö–æ–¥–Ω–∏–∫–µ TRADEDATE —É–Ω–∏–∫–∞–ª–µ–Ω, –ø–æ—ç—Ç–æ–º—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è
        if not df_all.empty:
            existing_dates = set(df_all["TRADEDATE"].astype("datetime64[ns]"))
            df_src = df_src[~df_src["TRADEDATE"].isin(existing_dates)]

        if df_src.empty:
            logger.info("–ù–µ—Ç –Ω–æ–≤—ã—Ö –±–∞—Ä–æ–≤ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            continue

        if df_all.empty:
            df_all = df_src.copy()
        else:
            df_all = pd.concat([df_all, df_src], ignore_index=True)

    if df_all.empty:
        logger.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
        logger.info("===== –ì–æ—Ç–æ–≤–æ (–ø—É—Å—Ç–æ) =====")
        return

    df_all = df_all.sort_values("TRADEDATE").reset_index(drop=True)

    logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ H2 –¥–ª—è {len(df_all)} –∑–∞–ø–∏—Å–µ–π")
    df_all = process_H2_nearest(df_all)
    print("–î–æ–ª—è NA –≤ H2:", df_all["H2"].isna().mean())
    print(df_all["H2"].describe())

    logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–∏–µ perc_25 –∏ perc_75 –¥–ª—è {len(df_all)} –∑–∞–ø–∏—Å–µ–π")
    df_all = df_all.sort_values("TRADEDATE").reset_index(drop=True)
    df_all = add_percentile_prev_trading_bars(df_all, bars_back=LOOKBACK_BARS)

    # print("–î–æ–ª—è NA –≤ perc_25:", df_all["perc_25"].isna().mean())
    # print(df_all["perc_25"].describe())
    # print("–î–æ–ª—è NA –≤ perc_75:", df_all["perc_75"].isna().mean())
    # print(df_all["perc_75"].describe())

    end = datetime.now()
    logger.info(f"===== –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {end - start} =====")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —à–∏—Ä–æ–∫–æ–≥–æ df pandas
    pd.options.display.width = 1200
    pd.options.display.max_colwidth = 100
    pd.options.display.max_columns = 100
    print(df_all)

    save_all(df_all)


if __name__ == "__main__":
    main()